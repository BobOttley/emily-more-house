// /static/realtime-voice-handsfree.js
(function () {
  // DOM
  const chatbox   = document.getElementById('penai-chatbox');
  const toggleBtn = document.getElementById('penai-toggle');

  const consent   = document.getElementById('voiceConsent');
  const agree     = document.getElementById('agreeVoice');
  const startBtn  = document.getElementById('startVoice');
  const cancelBtn = document.getElementById('cancelVoice');

  const headerLangSel = document.getElementById('language-selector');
  const consentLangSel= document.getElementById('vc-lang');

  const startHeaderBtn= document.getElementById('start-button');
  const pauseBtn      = document.getElementById('pause-button');
  const endBtn        = document.getElementById('end-button');
  const aiAudio       = document.getElementById('aiAudio');
  const indicator     = document.getElementById('voiceIndicator');

  // State
  let pc = null;           // RTCPeerConnection
  let dc = null;           // DataChannel
  let micStream = null;    // MediaStream
  let started = false;
  let isPaused = false;
  let sessionId = null;
  let familyId = null;
  let currentLang = headerLangSel?.value || 'en';

  // === Fallback watchdog ===
  let fallbackTimer = null;
  const FALLBACK_TIMEOUT_MS = 3000; // 3s

  function resetFallbackTimer() {
    if (fallbackTimer) clearTimeout(fallbackTimer);
    fallbackTimer = setTimeout(() => {
      console.warn("Ã¢Å¡ Ã¯Â¸Â No response from Emily, sending fallback.");
      playFallbackMessage("Sorry, I didnÃ¢â‚¬â„¢t catch that Ã¢â‚¬â€ could you repeat the question?");
    }, FALLBACK_TIMEOUT_MS);
  }

  function cancelFallbackTimer() {
    if (fallbackTimer) {
      clearTimeout(fallbackTimer);
      fallbackTimer = null;
    }
  }

  function playFallbackMessage(msg) {
    // Show in chat (if you have addMessage helper)
    if (typeof addMessage === "function") addMessage("PEN.ai", msg);

    // Speak it (force TTS via response.create)
    sendEvent({
      type: 'response.create',
      response: { instructions: msg }
    });
  }

  // Language Ã¢â€ â€™ Voice
  const voiceByLang = {
    en: 'shimmer', fr: 'alloy', es: 'verse',
    de: 'luna', zh: 'alloy', ar: 'luna',
    it: 'verse', ru: 'alloy'
  };

  // Localisation for consent
  const i18n = {
    en: { title:'Enable Emily (voice)', desc:'To chat by voice, we need one-time permission to use your microphone and play audio responses.', agree:'I agree to voice processing for this session.', cancel:'Not now', start:'Start conversation' },
    fr: { title:'Activer Emily (voix)', desc:'Pour discuter Ãƒ  la voix, nous avons besoin dÃ¢â‚¬â„¢une autorisation unique pour utiliser votre microphone et lire les rÃƒÂ©ponses audio.', agree:'JÃ¢â‚¬â„¢accepte le traitement vocal pour cette session.', cancel:'Pas maintenant', start:'Commencer la conversation' },
    es: { title:'Activar Emily (voz)', desc:'Para hablar por voz, necesitamos permiso ÃƒÂºnico para usar tu micrÃƒÂ³fono y reproducir respuestas de audio.', agree:'Acepto el procesamiento de voz para esta sesiÃƒÂ³n.', cancel:'Ahora no', start:'Iniciar conversaciÃƒÂ³n' },
    de: { title:'Emily (Sprache) aktivieren', desc:'FÃƒÂ¼r die Sprachfunktion benÃƒÂ¶tigen wir einmalige Berechtigung fÃƒÂ¼r Ihr Mikrofon und die Audiowiedergabe.', agree:'Ich stimme der Sprachverarbeitung fÃƒÂ¼r diese Sitzung zu.', cancel:'Nicht jetzt', start:'Konversation starten' },
    zh: { title:'Ã¥ÂÂ¯Ã§â€Â¨ EmilyÃ¯Â¼Ë†Ã¨Â¯Â­Ã©Å¸Â³Ã¯Â¼â€°', desc:'Ã¨Â¦ÂÃ¨Â¿â€ºÃ¨Â¡Å’Ã¨Â¯Â­Ã©Å¸Â³Ã¨ÂÅ Ã¥Â¤Â©Ã¯Â¼Å’Ã¦Ë†â€˜Ã¤Â»Â¬Ã©Å“â‚¬Ã¨Â¦ÂÃ¤Â¸â‚¬Ã¦Â¬Â¡Ã¦â‚¬Â§Ã¦Å½Ë†Ã¦ÂÆ’Ã¤Â½Â¿Ã§â€Â¨Ã¦â€šÂ¨Ã§Å¡â€žÃ©ÂºÂ¦Ã¥â€¦â€¹Ã©Â£Å½Ã¥Â¹Â¶Ã¦â€™Â­Ã¦â€Â¾Ã©Å¸Â³Ã©Â¢â€˜Ã¥â€ºÅ¾Ã¥Â¤ÂÃ£â‚¬â€š', agree:'Ã¦Ë†â€˜Ã¥ÂÅ’Ã¦â€žÂÃ¥Å“Â¨Ã¦Å“Â¬Ã¦Â¬Â¡Ã¤Â¼Å¡Ã¨Â¯ÂÃ¤Â¸Â­Ã¨Â¿â€ºÃ¨Â¡Å’Ã¨Â¯Â­Ã©Å¸Â³Ã¥Â¤â€žÃ§Ââ€ Ã£â‚¬â€š', cancel:'Ã¦Å¡â€šÃ¤Â¸Â', start:'Ã¥Â¼â‚¬Ã¥Â§â€¹Ã¥Â¯Â¹Ã¨Â¯Â' },
    ar: { title:'Ã˜ÂªÃ™ÂÃ˜Â¹Ã™Å Ã™â€ž Ã˜Â¥Ã™â€¦Ã™Å Ã™â€žÃ™Å  (Ã˜ÂµÃ™Ë†Ã˜Âª)', desc:'Ã™â€žÃ™â€žÃ˜Â¯Ã˜Â±Ã˜Â¯Ã˜Â´Ã˜Â© Ã˜Â¨Ã˜Â§Ã™â€žÃ˜ÂµÃ™Ë†Ã˜ÂªÃ˜Å’ Ã™â€ Ã˜Â­Ã˜ÂªÃ˜Â§Ã˜Â¬ Ã˜Â¥Ã™â€žÃ™â€° Ã˜Â¥Ã˜Â°Ã™â€  Ã™â€žÃ™â€¦Ã˜Â±Ã˜Â© Ã™Ë†Ã˜Â§Ã˜Â­Ã˜Â¯Ã˜Â© Ã™â€žÃ˜Â§Ã˜Â³Ã˜ÂªÃ˜Â®Ã˜Â¯Ã˜Â§Ã™â€¦ Ã˜Â§Ã™â€žÃ™â€¦Ã™Å Ã™Æ’Ã˜Â±Ã™Ë†Ã™ÂÃ™Ë†Ã™â€  Ã™Ë†Ã˜ÂªÃ˜Â´Ã˜ÂºÃ™Å Ã™â€ž Ã˜Â§Ã™â€žÃ˜Â±Ã˜Â¯Ã™Ë†Ã˜Â¯ Ã˜Â§Ã™â€žÃ˜ÂµÃ™Ë†Ã˜ÂªÃ™Å Ã˜Â©.', agree:'Ã˜Â£Ã™Ë†Ã˜Â§Ã™ÂÃ™â€š Ã˜Â¹Ã™â€žÃ™â€° Ã™â€¦Ã˜Â¹Ã˜Â§Ã™â€žÃ˜Â¬Ã˜Â© Ã˜Â§Ã™â€žÃ˜ÂµÃ™Ë†Ã˜Âª Ã™â€žÃ™â€¡Ã˜Â°Ã™â€¡ Ã˜Â§Ã™â€žÃ˜Â¬Ã™â€žÃ˜Â³Ã˜Â©.', cancel:'Ã™â€žÃ™Å Ã˜Â³ Ã˜Â§Ã™â€žÃ˜Â¢Ã™â€ ', start:'Ã˜Â¨Ã˜Â¯Ã˜Â¡ Ã˜Â§Ã™â€žÃ™â€¦Ã˜Â­Ã˜Â§Ã˜Â¯Ã˜Â«Ã˜Â©' },
    it: { title:'Abilita Emily (voce)', desc:'Per parlare con la voce, serve unÃ¢â‚¬â„¢autorizzazione una tantum per usare il microfono e riprodurre risposte audio.', agree:'Accetto lÃ¢â‚¬â„¢elaborazione vocale per questa sessione.', cancel:'Non ora', start:'Avvia conversazione' },
    ru: { title:'Ãâ€™ÃÂºÃÂ»Ã‘Å½Ã‘â€¡ÃÂ¸Ã‘â€šÃ‘Å’ Emily (ÃÂ³ÃÂ¾ÃÂ»ÃÂ¾Ã‘Â)', desc:'ÃÂ§Ã‘â€šÃÂ¾ÃÂ±Ã‘â€¹ ÃÂ¾ÃÂ±Ã‘â€°ÃÂ°Ã‘â€šÃ‘Å’Ã‘ÂÃ‘Â ÃÂ³ÃÂ¾ÃÂ»ÃÂ¾Ã‘ÂÃÂ¾ÃÂ¼, ÃÂ½ÃÂ°ÃÂ¼ ÃÂ½Ã‘Æ’ÃÂ¶ÃÂ½ÃÂ¾ Ã‘â‚¬ÃÂ°ÃÂ·ÃÂ¾ÃÂ²ÃÂ¾ÃÂµ Ã‘â‚¬ÃÂ°ÃÂ·Ã‘â‚¬ÃÂµÃ‘Ë†ÃÂµÃÂ½ÃÂ¸ÃÂµ ÃÂ½ÃÂ° ÃÂ¸Ã‘ÂÃÂ¿ÃÂ¾ÃÂ»Ã‘Å’ÃÂ·ÃÂ¾ÃÂ²ÃÂ°ÃÂ½ÃÂ¸ÃÂµ ÃÂ²ÃÂ°Ã‘Ë†ÃÂµÃÂ³ÃÂ¾ ÃÂ¼ÃÂ¸ÃÂºÃ‘â‚¬ÃÂ¾Ã‘â€žÃÂ¾ÃÂ½ÃÂ° ÃÂ¸ ÃÂ²ÃÂ¾Ã‘ÂÃÂ¿Ã‘â‚¬ÃÂ¾ÃÂ¸ÃÂ·ÃÂ²ÃÂµÃÂ´ÃÂµÃÂ½ÃÂ¸ÃÂµ ÃÂ°Ã‘Æ’ÃÂ´ÃÂ¸ÃÂ¾ÃÂ¾Ã‘â€šÃÂ²ÃÂµÃ‘â€šÃÂ¾ÃÂ².', agree:'ÃÂ¯ Ã‘ÂÃÂ¾ÃÂ³ÃÂ»ÃÂ°Ã‘ÂÃÂµÃÂ½ ÃÂ½ÃÂ° ÃÂ¾ÃÂ±Ã‘â‚¬ÃÂ°ÃÂ±ÃÂ¾Ã‘â€šÃÂºÃ‘Æ’ ÃÂ³ÃÂ¾ÃÂ»ÃÂ¾Ã‘ÂÃÂ° ÃÂ² Ã‘ÂÃ‘â€šÃÂ¾ÃÂ¼ Ã‘ÂÃÂµÃÂ°ÃÂ½Ã‘ÂÃÂµ.', cancel:'ÃÂÃÂµ Ã‘ÂÃÂµÃÂ¹Ã‘â€¡ÃÂ°Ã‘Â', start:'ÃÂÃÂ°Ã‘â€¡ÃÂ°Ã‘â€šÃ‘Å’ Ã‘â‚¬ÃÂ°ÃÂ·ÃÂ³ÃÂ¾ÃÂ²ÃÂ¾Ã‘â‚¬' }
  };

  // Localise consent UI
  const vcTitle = document.getElementById('vc-title');
  const vcDesc  = document.getElementById('vc-desc');
  const vcAgree = document.getElementById('vc-agree');

  function applyConsentLocale(lang) {
    const t = i18n[lang] || i18n.en;
    vcTitle.textContent = t.title;
    vcDesc.textContent  = t.desc;
    vcAgree.textContent = t.agree;
    cancelBtn.textContent = t.cancel;
    startBtn.textContent  = t.start;
  }

  function syncLanguage(lang) {
    currentLang = lang;
    if (headerLangSel && headerLangSel.value !== lang) headerLangSel.value = lang;
    if (consentLangSel && consentLangSel.value !== lang) consentLangSel.value = lang;
    applyConsentLocale(lang);
  }

  headerLangSel?.addEventListener('change', e => syncLanguage(e.target.value));
  consentLangSel?.addEventListener('change', e => syncLanguage(e.target.value));

  // Status indicator
  function showIndicator(stateText) {
    if (!indicator) return;
    indicator.textContent = stateText || 'Ready';
    indicator.classList.remove('hidden');
  }
  function hideIndicator() { indicator?.classList.add('hidden'); }

  function updateUIForStart() {
    started = true; isPaused = false;
    startHeaderBtn?.classList.add('hidden');
    pauseBtn?.classList.remove('hidden');
    endBtn?.classList.remove('hidden');
    if (pauseBtn) pauseBtn.textContent = 'Pause';
  }

  function updateUIForEnd() {
    started = false; isPaused = false;
    startHeaderBtn?.classList.remove('hidden');
    pauseBtn?.classList.add('hidden');
    endBtn?.classList.add('hidden');
    showIndicator('Ready');
  }

  function maybeShowConsent() {
    if (started) return;
    if (consent) {
      syncLanguage(currentLang);
      consent.style.display = 'flex';
    }
  }

  const observer = new MutationObserver(() => {
    if (chatbox?.classList.contains('open')) maybeShowConsent();
  });
  if (chatbox) observer.observe(chatbox, { attributes:true, attributeFilter:['class'] });

  toggleBtn?.addEventListener('click', () => {
    setTimeout(() => {
      if (chatbox?.classList.contains('open')) maybeShowConsent();
    }, 50);
  });

  // Consent interactions
  agree?.addEventListener('change', () => { startBtn.disabled = !agree.checked; });
  cancelBtn?.addEventListener('click', () => { consent.style.display = 'none'; });

  startHeaderBtn?.addEventListener('click', () => {
    if (!chatbox?.classList.contains('open')) chatbox.classList.add('open');
    if (consent) {
      agree.checked = false;
      startBtn.disabled = true;
      syncLanguage(currentLang);
      consent.style.display = 'flex';
    }
  });

  startBtn?.addEventListener('click', async () => {
    startBtn.disabled = true;
    showIndicator('ConnectingÃ¢â‚¬Â¦');
    try {
      await startVoiceSession();
      consent.style.display = 'none';
      updateUIForStart();
      showIndicator('ListeningÃ¢â‚¬Â¦');
    } catch (err) {
      console.error('Voice start error:', err);
      startBtn.disabled = false;
      showIndicator('Error');
      alert('Could not start voice. Please check mic permissions and try again.');
    }
  });

  pauseBtn?.addEventListener('click', () => {
    if (!micStream) return;
    const track = micStream.getAudioTracks()[0];
    if (!track) return;
    track.enabled = !track.enabled;
    isPaused = !track.enabled;
    pauseBtn.textContent = isPaused ? 'Resume' : 'Pause';
    showIndicator(isPaused ? 'Paused' : 'ListeningÃ¢â‚¬Â¦');
  });

  endBtn?.addEventListener('click', () => {
    teardownSession();
    updateUIForEnd();
  });

  document.addEventListener('visibilitychange', () => {
    if (!micStream) return;
    const enable = document.visibilityState === 'visible';
    micStream.getAudioTracks().forEach(t => t.enabled = enable && !isPaused);
  });
  window.addEventListener('beforeunload', teardownSession);

  // === Voice session ===
  async function startVoiceSession() {
    const sessRes = await fetch('/realtime/session', {
      method: 'POST',
      headers: {'Content-Type':'application/json'},
      body: JSON.stringify({
        model: 'gpt-4o-realtime-preview',
        voice: voiceByLang[currentLang] || 'shimmer',
        language: currentLang
      })
    });
    if (!sessRes.ok) throw new Error('Failed to create realtime session: ' + (await sessRes.text().catch(()=>'')));
    const sess = await sessRes.json();
    sessionId = sess.session_id;

    const token =
      sess.token ||
      (sess.session && sess.session.client_secret && (sess.session.client_secret.value || sess.session.client_secret)) ||
      (sess.client_secret && (sess.client_secret.value || sess.client_secret)) ||
      sess.value;
    if (!token) throw new Error('No ephemeral token returned');

    pc = new RTCPeerConnection();

    pc.ontrack = (e) => {
      if (aiAudio) {
        aiAudio.srcObject = e.streams[0];
        aiAudio.play().catch(()=>{});
      }
      cancelFallbackTimer(); // got audio, cancel watchdog
    };

    dc = pc.createDataChannel('oai-events');
    dc.onopen = () => {
      sendEvent({
        type: 'response.create',
        response: {
          instructions: `Please greet the user in their selected language (${currentLang}). Keep replies concise and helpful, and continue in this language unless they ask to switch.`
        }
      });
      resetFallbackTimer(); // start watchdog after greeting request
    };
    dc.onmessage = onEventMessage;

    micStream = await navigator.mediaDevices.getUserMedia({
      audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true },
      video: false
    });
    micStream.getTracks().forEach(t => pc.addTrack(t, micStream));

    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const sdpRes = await fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/sdp'
      },
      body: offer.sdp
    });
    if (!sdpRes.ok) throw new Error('Realtime SDP error: ' + (await sdpRes.text().catch(()=>'')));

    const answer = { type:'answer', sdp: await sdpRes.text() };
    await pc.setRemoteDescription(answer);
  }

  function sendEvent(obj){
    if (dc && dc.readyState === 'open') {
      dc.send(JSON.stringify(obj));
    }
  }

  function onEventMessage(evt){
    let msg; try{ msg = JSON.parse(evt.data); } catch { return; }
    console.log("ðŸ“¥ Voice event:", msg.type);
    switch (msg.type) {
      case 'input_audio_buffer.speech_started':
        showIndicator('ListeningÃ¢â‚¬Â¦'); break;
      case 'input_audio_buffer.speech_stopped':
        showIndicator('ThinkingÃ¢â‚¬Â¦');
        resetFallbackTimer(); // user finished Ã¢â€ â€™ wait for reply
        break;
      case 'response.audio.started':
        showIndicator('SpeakingÃ¢â‚¬Â¦');
        cancelFallbackTimer(); // reply began
        break;
      case 'response.audio.done':
        showIndicator('ListeningÃ¢â‚¬Â¦');
        cancelFallbackTimer(); // reply finished
        break;

      // Handle function calls
      case 'response.function_call_arguments.done':
        // Emily called a tool - execute it
        handleToolCall(msg);
        break;

      default: break;
    }
  }


  async function handleToolCall(msg) {
    const callId = msg.call_id;
    const functionName = msg.name;
    let args = {};

    try {
      args = JSON.parse(msg.arguments);
    } catch (e) {
      console.error('Failed to parse tool arguments:', e);
    }

    console.log(`ðŸ”§ Tool called: ${functionName}`, args);

    let result = null;
    let error = null;

    try {
      if (functionName === 'send_enquiry_email') {
        showIndicator('Sending emailâ€¦');

        const response = await fetch('/realtime/tool/send_enquiry_email', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            parent_name: args.parent_name,
            parent_email: args.parent_email,
            parent_phone: args.parent_phone,
            message: args.message
          })
        });

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }

        const data = await response.json();
        result = data;
        console.log('âœ… Email sent');

      } else if (functionName === 'get_open_days') {
        const response = await fetch('/realtime/tool/get_open_days', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' }
        });

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }

        result = await response.json();
        console.log('âœ… Open days fetched');

      } else if (functionName === 'kb_search') {
        const response = await fetch('/realtime/tool/kb_search', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ query: args.query })
        });

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }

        result = await response.json();
        console.log('âœ… KB search completed');

      } else {
        error = `Unknown tool: ${functionName}`;
      }

    } catch (e) {
      console.error(`Tool execution error:`, e);
      error = e.message;
    }

    // Send the result back to Emily
    sendEvent({
      type: 'conversation.item.create',
      item: {
        type: 'function_call_output',
        call_id: callId,
        output: error ? JSON.stringify({ error }) : JSON.stringify(result)
      }
    });

    // Tell Emily to generate a response with the tool result
    sendEvent({
      type: 'response.create'
    });
  }
  function teardownSession() {
    try { micStream?.getTracks().forEach(t => t.stop()); } catch {}
    try { pc?.close(); } catch {}
    micStream = null; pc = null; dc = null; sessionId = null;
    cancelFallbackTimer();
  }

  const urlParams = new URLSearchParams(window.location.search);
  familyId = urlParams.get('family_id') || urlParams.get('id') || null;

  syncLanguage(currentLang);
})();